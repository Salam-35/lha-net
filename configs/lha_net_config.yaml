# LHA-Net Configuration
# Lightweight Hierarchical Attention Network for AMOS22 Small Organ Segmentation

model:
  name: "lha_net"
  type: "lightweight"  # Options: lightweight, standard, high_capacity

  # Architecture parameters
  in_channels: 1
  num_classes: 16
  backbone_type: "resnet18"  # Options: resnet18, resnet34
  use_lightweight: true
  base_channels: 32

  # PMSA configuration
  pmsa_scales: [0.5, 0.75, 1.0, 1.25, 1.5]
  organ_contexts: ["small", "small", "medium", "medium", "large"]

  # Decoder configuration
  use_deep_supervision: true

  # Memory optimization
  memory_efficient: true
  use_gradient_checkpointing: true

# Training configuration
training:
  # Basic training parameters
  num_epochs: 100
  batch_size: 1  # Physical batch size (will use gradient accumulation)
  effective_batch_size: 16  # Effective batch size through accumulation

  # Learning rate and optimization
  learning_rate: 0.001
  optimizer:
    type: "adamw"
    weight_decay: 0.0001
    betas: [0.9, 0.999]
    eps: 0.00000001
    differential_lr: true
    backbone_lr_factor: 0.1

  # Learning rate scheduling
  scheduler:
    type: "cosine_warmup"
    warmup_epochs: 5
    min_lr: 0.000001

  # Mixed precision training
  mixed_precision:
    enabled: true
    init_scale: 65536.0
    growth_factor: 2.0
    backoff_factor: 0.5

  # Gradient accumulation and clipping
  gradient_accumulation_steps: 8  # effective_batch_size / batch_size
  max_grad_norm: 1.0

  # Memory management
  memory_optimization:
    enable_checkpointing: true
    empty_cache_freq: 10
    pin_memory: true
    dynamic_batch_sizing: false  # Experimental

  # Validation
  validation_freq: 1  # Validate every N epochs (1 = every epoch)
  detailed_metrics_freq: 5  # Compute detailed metrics (HD95, NSD) every N epochs (slower)
  save_freq: 5  # Save checkpoint every N epochs

# Loss function configuration
loss:
  primary_loss_weight: 1.0
  deep_supervision_weight: 0.4
  size_prediction_weight: 0.1
  routing_weight: 0.05

  # Combo loss weights
  focal_weight: 0.5
  dice_weight: 0.3
  size_weight: 0.2

  # Adaptive focal loss
  focal_loss:
    gamma: 2.0
    adaptive_gamma: true
    size_aware_alpha: true
    organ_size_weights:
      small: 3.0
      medium: 2.0
      large: 1.0
      background: 0.1

  # Size weighted loss
  size_weighted_loss:
    volume_adaptive: true
    spatial_weighting: true
    boundary_emphasis: 2.0

# Data configuration
data:
  # Patch sampling
  patch_size: [48, 96, 96]  # [D, H, W] - reduced for 12GB GPU
  overlap_ratio: 0.5
  patches_per_volume: 16

  # Smart sampling strategy
  smart_sampling:
    small_organ_bias: 0.7
    boundary_bias: 0.2
    random_bias: 0.1
    min_organ_voxels: 10
    difficulty_weights:
      small: 4.0
      medium: 2.5
      large: 1.0
      boundary: 3.0
      background: 0.5

  # Preprocessing
  preprocessing:
    target_spacing: [1.5, 1.5, 1.5]  # mm
    intensity_normalization: "z_score"  # Options: z_score, min_max, percentile
    clip_range: [-200, 300]  # HU

  # Data augmentation
  augmentation:
    enabled: false
    rotation_range: [-15, 15]  # degrees
    scaling_range: [0.9, 1.1]
    intensity_shift_range: [-0.1, 0.1]
    intensity_scale_range: [0.9, 1.1]
    elastic_deformation: false  # Disabled for memory efficiency
    random_flip: true
    gaussian_noise_std: 0.01

  # (removed organ_names; see top-level `labels` instead)

# Hardware and system configuration
system:
  # Device configuration
  device: "cuda"  # Options: cuda, cpu, auto
  gpu_id: 0

  # Memory constraints
  max_gpu_memory_gb: 24  # RTX 4090
  max_system_memory_gb: 64

  # Parallel processing
  num_workers: 4
  pin_memory: true
  prefetch_factor: 2

  # Logging and monitoring
  log_interval: 50
  memory_log_interval: 100
  wandb_project: "lha-net-amos22"
  experiment_name: "lha_net_v1"

# Evaluation configuration
evaluation:
  metrics:
    - "dice"
    - "hausdorff_95"
    - "normalized_surface_distance"
    - "volume_similarity"
  # Compute HD95/NSD on a limited number of validation cases when detailed
  # Set 0 to use all validation cases
  detailed_sample_cases: 15

  # Statistical analysis
  statistical_tests: true
  confidence_level: 0.95

  # Organ grouping for analysis
  organ_groups:
    small: [9, 12]  # gallbladder, duodenum
    medium: [7, 8]  # adrenal glands
    large: [1, 2, 3, 4, 5, 6, 10, 11, 13]  # rest

# Paths configuration (to be set by user)
paths:
  data_root: "/media/salam/projects/amos22/data/amos/"
  output_dir: "/media/salam/projects/amos22/lha-net/"
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"

  # Preprocessed data (optional)
  preprocessed_dir: null  # Will preprocess if null

# Reproducibility
random_seed: 42
deterministic: false  # Set to true for full reproducibility (slower)

# Experimental features
experimental:
  # Curriculum learning
  curriculum_learning: false
  curriculum_start_epoch: 10

  # Progressive resizing
  progressive_resizing: false
  initial_patch_size: [64, 64, 64]
  final_patch_size: [96, 128, 128]

# Labels mapping: class index -> human-readable name
# All scripts (train/test/inference) will use these for per-class names.
labels:
  "0": "background"
  "1": "spleen"
  "2": "right kidney"
  "3": "left kidney"
  "4": "gall bladder"
  "5": "esophagus"
  "6": "liver"
  "7": "stomach"
  "8": "arota"
  "9": "postcava"
  "10": "pancreas"
  "11": "right adrenal gland"
  "12": "left adrenal gland"
  "13": "duodenum"
  "14": "bladder"
  "15": "prostate/uterus"

  # EMA (Exponential Moving Average)
  use_ema: false
  ema_decay: 0.999

  # Look-ahead optimizer
  use_lookahead: false
  lookahead_k: 5
  lookahead_alpha: 0.5
